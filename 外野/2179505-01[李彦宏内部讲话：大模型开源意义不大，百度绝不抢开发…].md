
*****

####  天穹观测者  
##### 1#       楼主       发表于 2024-4-11 19:50

新浪科技独家获取到一则李彦宏内部讲话，在内部讲话中，李彦宏对大模型开源与闭源的路线选择以及 AI 创业者应该专注模型还是应用等业界焦点话题，发表了自己的看法。李彦宏认为，闭源模型在能力上会持续地领先，而不是一时地领先。模型开源也不是一个众人拾柴火焰高的情况。这跟传统的软件开源一比如 Linux、安卓等等很不一样 “闭源，是有真正的商业模式的，是能够赚到钱的，能够赚到钱才能聚集算力、聚集人才，闭源在成本上反而是有优势的，只要是同等能力，闭源模型的推理成本一定是更低的，响应速度一定是更快的。” 李彦宏表示。李彦宏认为，对于 AI 创业者来说，核心竞争力本就不应该是模型本身，这太耗资源了，而且需要非常长时间的坚持才能跑出来。（新浪科技）

*****

####  lilisipis  
##### 2#       发表于 2024-4-11 19:52

艳红能不能把贴吧弱智AI给关了

*****

####  Ouro_Kronii  
##### 3#       发表于 2024-4-11 19:56

所以说朱啸虎话糙理不糙啊

*****

####  炽十二翼  
##### 4#       发表于 2024-4-11 19:57

<img src="https://static.saraba1st.com/image/smiley/face2017/049.png" referrerpolicy="no-referrer">没能力直说，弱智文心能关了吗？

*****

####  icowei  
##### 5#       发表于 2024-4-11 19:58

《赚钱》

*****

####  诚司  
##### 6#       发表于 2024-4-11 19:58

 本帖最后由 诚司 于 2024-4-11 20:00 编辑 

李艳红这话明显是用屁股说的，但问题是屁股有时候也会说真话，真的确实如此<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

如果是llama这种稍微弱点的还好，我现在也不知道这么多家巨头像活菩萨一样把这么强的模型开源出来到底有什么好处，也别说闭源一定比开源强，闭源不是个个都像chatgpt和claude，能强过那几个最强开源模型的有几家啊<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">，这么做看起来唯一利好的也就是老黄（可能也包括华为）

*****

####  cyberalogo  
##### 7#       发表于 2024-4-11 20:02

What's Your Problem？<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  mythgogo  
##### 8#       发表于 2024-4-11 20:04

开源不就让你们知道我的大模型全是用用户隐私数据炼出来的了

*****

####  诚司  
##### 9#       发表于 2024-4-11 20:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64562556&amp;ptid=2179505" target="_blank">mythgogo 发表于 2024-4-11 20:04</a>

开源不就让你们知道我的大模型全是用用户隐私数据炼出来的了</blockquote>
大模型需要的是完整的高质量文本，顶多只有腾讯可能有能算得上用户隐私而且还值得用来练的数据，其他公司业务上就不存在这么多东西

谁拿鸡毛蒜皮的淘宝买飞机杯和客服撕逼记录当训练数据啊<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

当然，如果是网上公开的数据里的“隐私”，那可多了去了，用base模型（非chat）直接把黄文输进去文本补全，大模型能给你补全个作者出来<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  酷乐  
##### 10#       发表于 2024-4-11 20:48

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64562502&amp;ptid=2179505" target="_blank">炽十二翼 发表于 2024-4-11 19:57</a>

没能力直说，弱智文心能关了吗？</blockquote>
你都不知道，百度翻译新上的“AI翻译”贼强，虽然目前只支持“中英互译”，但已经把DeepL秒得找不着北……

像我这些帖就是用它翻译后修改的：
[https://bbs.saraba1st.com/2b/thread-2178854-1-1.html](https://bbs.saraba1st.com/2b/thread-2178854-1-1.html)
[https://bbs.saraba1st.com/2b/for ... 86&amp;pid=64553952](https://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;ptid=2179286&amp;pid=64553952)

你拿这些文字去DeepL，效果就差远了，而且第二个还没法一次翻那么长。

*****

####  广东侠  
##### 11#       发表于 2024-4-11 20:57

文心要是弱智，那恐怕除了微软以外的都是弱智，微软本身得算轻度弱智

*****

####  fwt001  
##### 12#       发表于 2024-4-11 21:00

彦宏是吃过苦的,穷怕了,这辈子先把钱的事弄了,下辈子再聊别的

*****

####  naclken.  
##### 13#       发表于 2024-4-11 21:02

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64562508&amp;ptid=2179505" target="_blank">诚司 发表于 2024-4-11 19:58</a>

李艳红这话明显是用屁股说的，但问题是屁股有时候也会说真话，真的确实如此

如果是llama这种稍微弱 ...</blockquote>
闭源模型的条条框框太多了

这就好比买单机游戏和买联机游戏一样

单机游戏你随便叮，联机游戏开挂是禁止的

*****

####  zeroboss1  
##### 14#       发表于 2024-4-11 21:03

本质上说现在的大企业开源就是为了对抗微软。。。。

*****

####  Herreimu  
##### 15#       发表于 2024-4-11 21:03

文心跟qwen、百川那几个开源的比如何？

*****

####  水雲逸  
##### 16#       发表于 2024-4-11 21:09

<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">那百度怎么没比别人先开发出来呢，别人一开源国内就都有突破了

—— 来自 OnePlus PJA110, Android 14上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  王怡人  
##### 17#       发表于 2024-4-11 21:10

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64563184&amp;ptid=2179505" target="_blank">Herreimu 发表于 2024-4-11 21:03</a>

文心跟qwen、百川那几个开源的比如何？</blockquote>
文心比开源的qwen更强, 开源的qwen首先不是全参数的,  最大只有72B, 其次qwen去年12月闭源版本就更新到了2.1,  而现在开源的也只是1.5版,  无论是版本还是参数量都是残废, 满血版qwen2.1比文心强,  但是两方面都阉割的开源qwen自然不如文心了

*****

####  诚司  
##### 18#       发表于 2024-4-11 21:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64563245&amp;ptid=2179505" target="_blank">水雲逸 发表于 2024-4-11 21:09</a>

那百度怎么没比别人先开发出来呢，别人一开源国内就都有突破了

—— 来自 OnePlus PJA110, Android ...</blockquote>
大模型领域扯什么“别人一开源国内就突破”可太搞笑了，有种把别人尸体的脑子拿过来装到自己脑子里的那种美<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  王怡人  
##### 19#       发表于 2024-4-11 21:34

普通的程序, 开源之后社区开发者可以贡献代码, 因此开源之后可以帮助程序的发展进步, 但是大模型确实开源没用, 这玩意本身就是个黑箱,  社区开发者根本没办法贡献代码,   绝大部分的所谓开源模型本身只开源权重, 就像马斯克的那个,  他就是把黑箱给你下载了,  训练代码不会给你开源的,  训练用的数据集也不会给你开源的,  这种所谓的开源本质上跟闭源没区别, 完全可以类比为他把编译后的二进制文件开放给你下载,  只开放二进制文件的下载而不开放源代码下载, 这种其实就是闭源的原本定义,  所以绝大多数的所谓开源大模型, 性质上应该更接近闭源共享软件, 而不是开源.

根据我在国内开源模型开发社区里的观察,  因为开源模型与闭源模型性能上的差异,  开源模型基本上都是当玩具研究的,   真正想当产品开发的只能使用性能最强的api,  所以就算你模型开源得再好,  人家用你的开源模型开发的应用要是想迁移到性能最强的闭源api上基本就是改几行代码的事, 这方面基本不存在生态护城河. 而如果你一开始就计划使用最强的api来运营你的应用, 那为什么不直接在开发的时候就用api呢?  毕竟高性能的模型与低性能的模型差距还是蛮大的, 你在低性能模型上的调优很可能在高性能模型上完全失效.

*****

####  hollowd  
##### 20#       发表于 2024-4-11 21:34

我记得百度在gpt出来前就耕耘AI了吧，还说什么ALL in AI，结果还是gpt大火，才把文心一言端出来。有种过河拆桥的美

*****

####  ycjiang1337  
##### 21#       发表于 2024-4-11 21:52

 本帖最后由 ycjiang1337 于 2024-4-11 21:54 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64563245&amp;ptid=2179505" target="_blank">水雲逸 发表于 2024-4-11 21:09</a>
那百度怎么没比别人先开发出来呢，别人一开源国内就都有突破了

—— 来自 OnePlus PJA110, Android ...</blockquote>
笑死，果然土殖之所以恶心是因为土，先不说你所谓的“别人开源”的llama跟文心一言初版基本上前后脚上线，目前llama2不仅不支持中文而且性能不如文心4一根毛，现在全球范围内非MoE最强的开源模型是阿里的通义千问72B，所以谁突破谁？

—— 来自 HUAWEI ALN-AL80, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  novalli  
##### 22#       发表于 2024-4-11 21:59

大模型开源本质上是科研习惯带入到了商业中，因为大模型这个领域的科研和商业之间几乎是无缝衔接，而科研几乎是必然开源（准确来说我都没想到哪个理论是没开源的），不然没办法做同行评议（没办法复现）。
现在开始真正进入商业逻辑形成商品的话，闭源才是正常做法。目前还没办法确定开源和闭源的优劣势都有哪些，但闭源至少做到了“对用户隐藏技术细节”，是比较合理的路径。对商品的评价就应该回到对使用价值的评价上去，而开源与否应该是一个附加的价值。

—— 来自 Xiaomi 2206123SC, Android 14上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.1.2

*****

####  诚司  
##### 23#       发表于 2024-4-11 22:18

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64563949&amp;ptid=2179505" target="_blank">novalli 发表于 2024-4-11 21:59</a>

大模型开源本质上是科研习惯带入到了商业中，因为大模型这个领域的科研和商业之间几乎是无缝衔接，而科研几 ...</blockquote>
为了同行评议直接放个api就行，closeAI不就这么干的吗<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

我都怀疑开源这么多大参数模型是closeAI偷着支持的，有mistral和Qwen这种开源模型在，就算再便宜，谁还用那些不如chatgpt的api接口啊

之前我给人画饼做了一个text2sql再转逻辑规则的demo，本来是在我笔记本上的Qwen7B int4上做的，到单位机器上没gpu，我就用kimichat的api，结果这任务上kimichat连7B量化的Qwen都不如，尬死我了<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  王怡人  
##### 24#       发表于 2024-4-11 22:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64563184&amp;ptid=2179505" target="_blank">Herreimu 发表于 2024-4-11 21:03</a>

文心跟qwen、百川那几个开源的比如何？</blockquote>
我印象中看过海思架构师通过成本反推认为文心免费版使用的模型最多只有6B的参数, 因为百度明显不打算在大模型的2C领域搞烧钱抢市场这套,  所以一开始就不准备亏本,  于是百度不仅是国内第一个收费的大模型, 免费版也特别地拉,  但是收费的文心3.5api版就明显很强, 这个我有亲自用过api , 确实比gpt3.5强得多, 哪怕是跟被认为国内最强的chatglm的api版相比我个人感受也是不相上下, 而gpt3.5免费版根据微软的分析大概是20B参数,  6B参数的模型比20B弱非常正常. 所以不要拿gpt3.5与gpt4的差距来想象文心3.5网页版与文心4的差距, 后者之间的差距要大得多.

*****

####  魔幻台北  
##### 25#       发表于 2024-4-11 22:23

所以

openai 闭源？

*****

####  诚司  
##### 26#       发表于 2024-4-11 22:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64564233&amp;ptid=2179505" target="_blank">王怡人 发表于 2024-4-11 22:20</a>

我印象中看过海思架构师通过成本反推认为文心免费版使用的模型最多只有6B的参数, 因为百度明显不打算在大 ...</blockquote>
免费版6B我不信的，那得是天顶星科技，gpt3.5是20B那作者也改了，就算是微软也不会人人都知道这种秘密的，商汤他们的文章里还写gpt3.5是200B呢，都是乱写罢了

百度的人告诉我的，肯定靠谱的消息，带文心一言的千帆平台，本地版，大约需要3台8卡A100 40G。按这个具体怎么推参数那就各自猜吧。千帆应该不是全量训练，反正单台8卡A100微调72B，不量化用lora是没问题的

*****

####  王怡人  
##### 27#       发表于 2024-4-11 22:29

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64564297&amp;ptid=2179505" target="_blank">诚司 发表于 2024-4-11 22:25</a>

免费版6B我不信的，那得是天顶星科技，gpt3.5是20B那作者也改了，就算是微软也不会人人都知道这种秘密的 ...</blockquote>
免费版特别拉, 百度一直被嘲笑就是因为这个免费版的表现, 根据qwen各个大小参数模型的表现, 我觉得免费版是6B模型并不夸张.

*****

####  f100333  
##### 28#       发表于 2024-4-11 22:31

百度贴吧有个机器人一直回答问题，主要是答案又是很多错误的。答了其实也没有什么

当我在贴吧搜索的时候发现，搜索出来一大半是这个ai的，十分绝望，找真人有用的信息找半天

*****

####  诚司  
##### 29#       发表于 2024-4-11 22:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64564341&amp;ptid=2179505" target="_blank">王怡人 发表于 2024-4-11 22:29</a>

免费版特别拉, 百度一直被嘲笑就是因为这个免费版的表现, 根据qwen各个大小参数模型的表现, 我觉得免费版 ...</blockquote>
信息抽取和函数级的code summary两个任务，免费版文心一言比qwen7B强114514倍，比chatglm2-6b强1919810倍了，百度名声差各种找bad case的人多，实际工业用百度6b能这水平那可太牛逼了

*****

####  王怡人  
##### 30#       发表于 2024-4-11 22:49

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64564390&amp;ptid=2179505" target="_blank">诚司 发表于 2024-4-11 22:33</a>

信息抽取和函数级的code summary两个任务，免费版文心一言比qwen7B强114514倍，比chatglm2-6b强1919810倍 ...</blockquote>
这种任务可以通过调用计算器或者解释器进行针对性优化

*****

####  诚司  
##### 31#       发表于 2024-4-11 22:53

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64564608&amp;ptid=2179505" target="_blank">王怡人 发表于 2024-4-11 22:49</a>

这种任务可以通过调用计算器或者解释器进行针对性优化</blockquote>
怎么可能，我测的一个是长文本（相对较长，免费版限制字数2000）阅读理解信息抽取，需要多跳推理那种

一个是ida生成的伪代码的理解，调编译器都编译不了好吧<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

哪怕免费版，我测过的一些写和读汇编代码的case都比gpt4强

*****

####  王怡人  
##### 32#       发表于 2024-4-11 23:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64564632&amp;ptid=2179505" target="_blank">诚司 发表于 2024-4-11 22:53</a>

怎么可能，我测的一个是长文本（相对较长，免费版限制字数2000）阅读理解信息抽取，需要多跳推理那种

一个 ...</blockquote>
很久没用过网页版的文心3.5了, 也许是现在的模型能力进步很大,  从superclue的测试里就能看出qwen1.5 7B的模型能力就比qwen 14B的强, 所以我觉得不能用比qwen 14B的能力强来判断其参数量一定大于14B,  毕竟现在的文心应该是qwen2.1的水平

<img src="https://img.saraba1st.com/forum/202404/11/230150rl8y84lvgqgog45q.jpg" referrerpolicy="no-referrer">

<strong>QQ截图20240411225716.jpg</strong> (110.62 KB, 下载次数: 0)

下载附件

2024-4-11 23:01 上传

*****

####  诚司  
##### 33#       发表于 2024-4-11 23:05

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64564728&amp;ptid=2179505" target="_blank">王怡人 发表于 2024-4-11 23:01</a>

很久没用过网页版的文心3.5了, 也许是现在的模型能力进步很大,  从superclue的测试里就能看出qwen1.5 7B ...</blockquote>
文心一言最开始版本据说是用bert结构实现的，毕竟千帆上就叫ERNIE-Bot，那拉胯很正常，和T5坐一桌。现在其实也没有很拉胯了

*****

####  油条小贩  
##### 34#       发表于 2024-4-12 00:47

要相信百度选择业务方向的能力，也要相信百度能把所有业务搞砸的能力

*****

####  ambivalence  
##### 35#       发表于 2024-4-12 00:53

根据文心免费版的表现你告诉我这是6B模型我是打死也不信的<img src="https://static.saraba1st.com/image/smiley/face2017/029.png" referrerpolicy="no-referrer">

*****

####  DeepFishing  
##### 36#       发表于 2024-4-12 01:16

这么看路奇当年的all in ai战略还是多少有点道理的？
纠结开不开源商不商业从一开始心态就输了，这玩意有点类似吹泡泡和赛博军备，居然想现在就能赚到钱。

—— 来自 Xiaomi 22041211AC, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  卢迪乌斯  
##### 37#       发表于 2024-4-12 02:13

这个我懂，最强的商业路线就是

别人开源

我闭源

*****

####  mimighost  
##### 38#       发表于 2024-4-12 03:39

 本帖最后由 mimighost 于 2024-4-12 03:42 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64563949&amp;ptid=2179505" target="_blank">novalli 发表于 2024-4-11 21:59</a>

大模型开源本质上是科研习惯带入到了商业中，因为大模型这个领域的科研和商业之间几乎是无缝衔接，而科研几 ...</blockquote>
大模型开源的确没用

大的模型99.99%的人跑都跑不起来，背后的逻辑和开源代码已经完全不一样了。开源等于开给竞争对手，那为啥要开源，做慈善么？所以只有字面意义的loser才会开源，比如马老板的xai，因为闭源根本没人会去碰他的东西，开源还能维持一点儿存在感。法国那个mistral同理，开源他就是开源之光，闭源正眼看他的都没有，就拿质量和gpt4老版本都没法比，更别提和opus这些怪物比了。

消费硬件要是能轻松跑70b的模型，开源还点儿用，但是也不大，因为70b本质也就玩儿，现在真正能用的大模型也就2.5家，开源的通通不能打。

*****

####  mimighost  
##### 39#       发表于 2024-4-12 09:51

开源的商业逻辑的根本在于免费去和付费竞争，抢夺“终端用户”，占领市场。终端用户是最后要付钱的那个人。如果你是消费软件，那终端用户就是消费者，如果你是企业，那用户就是企业，比如红帽的linux，就是企业拿去直接部署。

开源大模型逻辑崩溃了，因为真正使用你api的人，这群付费的消费者，他们并不会对开源的人产生依赖或者品牌认知，他们只能通过二道贩子的云计算厂商来使用你的api，所有的付费实际上在云计算厂和消费者之间完成。所以你开源了一毛钱都捞不到，你看stable不就崩溃了？

所以这种模式只有一条路子，那就是不开源，或者只开源弱智版本，真正高级的模型自己提供hosting，然后通过api计费，低价占领市场打价格战。就是openai正在做的事情

*****

####  阿酷怕苦  
##### 40#       发表于 2024-4-12 09:54

我现在写稿子必用文心了，经常用你就会发现，它的进步非常明显。


*****

####  ycjiang1337  
##### 41#       发表于 2024-4-12 09:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64564233&amp;ptid=2179505" target="_blank">王怡人 发表于 2024-4-11 22:20</a>
我印象中看过海思架构师通过成本反推认为文心免费版使用的模型最多只有6B的参数, 因为百度明显不打算在大 ...</blockquote>
现在非常尴尬的是文心4和GLM4有来有回，但是GLM4可以免费用…

—— 来自 HUAWEI ALN-AL80, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4

*****

####  ycjiang1337  
##### 42#       发表于 2024-4-12 09:58

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64564770&amp;ptid=2179505" target="_blank">诚司 发表于 2024-4-11 23:05</a>
文心一言最开始版本据说是用bert结构实现的，毕竟千帆上就叫ERNIE-Bot，那拉胯很正常，和T5坐一桌。现在 ...</blockquote>
到底谁先传的用BERT…能用BERT结构做生成任务那可比GPT还牛逼了

—— 来自 HUAWEI ALN-AL80, Android 12上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.4


*****

####  hbxsdfx  
##### 43#       发表于 2024-4-12 10:10

百度、阿里、腾讯已经切入到我们这个细分行业里了，做垂直领域的行业大模型，确实是有人买单的

*****

####  诚司  
##### 44#       发表于 2024-4-12 10:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64567466&amp;ptid=2179505" target="_blank">ycjiang1337 发表于 2024-4-12 09:58</a>

到底谁先传的用BERT…能用BERT结构做生成任务那可比GPT还牛逼了

—— 来自 HUAWEI ALN-AL80, Android 12 ...</blockquote>
我没深入用过最初版的文心一言，也没详细比过

不过T5的对话版，硬说的话也没那么烂，2023了也都还有codeT5+这样的工作，code summary方面也还可以的<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  kqwert  
##### 45#       发表于 2024-4-12 10:15

做第一个开源的人有意义，做第二个还有什么用吗


*****

####  TiiTiiLL  
##### 46#       发表于 2024-4-12 10:27

llm开源的一大尴尬点是大部分科研势的资源finetune一个7B的模型就够呛了，企业那种规模的llm连做inference都够呛，开源了后基本就是企业间相互白嫖

*****

####  折中旗帜鲜明  
##### 47#       发表于 2024-4-12 10:28

<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">别的没用过不好说，但贴吧包打听是真的弱智AI，完全就是编一段内容瞎回复


*****

####  archfriend12  
##### 48#       发表于 2024-4-12 10:35

开源的抄就完事了，的确不用抢<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">


*****

####  诚司  
##### 49#       发表于 2024-4-12 10:40

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64567826&amp;ptid=2179505" target="_blank">TiiTiiLL 发表于 2024-4-12 10:27</a>

llm开源的一大尴尬点是大部分科研势的资源finetune一个7B的模型就够呛了，企业那种规模的llm连做inference ...</blockquote>
7B和33B以上真的天差地别的，特别是long context

lora finetune 33B其实没这么废资源，QLora那更是了，72B的用QLora其实才70G显存，消费级的卡几张就够了

不过全参明显学术界和开源届就没跟上，或者没想去跟，megatron的代码用来训练llm的开源资料少得可怜，开源的遍地deepspeed，明显都是lora训的

不过megatron方面开源的也是阿里比较多，Qwen72B也开源，Pai-megatron-Path也开源，阿里这是化身铁拳要打爆大模型初创公司是吧<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">


*****

####  五块小民  
##### 50#       发表于 2024-4-12 11:01

开源是为了培养用户抢生态，打破高性能ai模型的垄断。闭源你做不到前列，用户就差一大截了。你要是低价促销就覆盖不了研发费用，那还不如开源赚点吆喝呢


*****

####  焚舟  
##### 51#       发表于 2024-4-12 11:41

搭车问下，普通搬砖码农办公用，现在文心一言付费版值得吗？和gpt4比咋样？


*****

####  mimighost  
##### 52#       发表于 2024-4-12 13:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64567826&amp;ptid=2179505" target="_blank">TiiTiiLL 发表于 2024-4-12 10:27</a>

llm开源的一大尴尬点是大部分科研势的资源finetune一个7B的模型就够呛了，企业那种规模的llm连做inference ...</blockquote>
就那些组，一个组才8张a100，还要养几个博士生，llm还是算了吧

llm是真富哥的玩意儿，没卡那就是上那美克星之前的孙悟空，有卡就是弗利萨

没卡的我看都转向llm evaluation这个赛道了，说白了就是个上游模型商抓虫罢了，免费的beta tester


*****

####  TiiTiiLL  
##### 53#       发表于 2024-4-12 15:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64570087&amp;ptid=2179505" target="_blank">mimighost 发表于 2024-4-12 13:11</a>

就那些组，一个组才8张a100，还要养几个博士生，llm还是算了吧

llm是真富哥的玩意儿，没卡那就是上那美克 ...</blockquote>
大部分院校的情况是8张A100整个院排队用


*****

####  Aerooxx  
##### 54#       发表于 2024-4-12 17:19

 本帖最后由 Aerooxx 于 2024-4-12 17:20 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=64568867&amp;ptid=2179505" target="_blank">焚舟 发表于 2024-4-12 11:41</a>

搭车问下，普通搬砖码农办公用，现在文心一言付费版值得吗？和gpt4比咋样？ ...</blockquote>
直接智谱清言GLM4啊，免费，CodeGeex也是免费的，看另一个码农代码辅助楼评价不错

