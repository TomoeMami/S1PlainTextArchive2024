
*****

####  alixsander  
##### 1#       楼主       发表于 2024-12-22 12:57

 本帖最后由 alixsander 于 2024-12-22 16:55 编辑 

过去一天了没人讨论

基准测试结果：

ARC-AGI测试：87.5% 

Codeforces Elo评分：2727

AIME 2024数学竞赛：96.7% 

GPQA Diamond测试：87.7%

FrontierMath:25.2%

<img src="https://preview.redd.it/its-happening-right-now-v0-q17ugujex48e1.jpeg?auto=webp&amp;s=0559c2065479501f445188db76584712574b9035" height="855" id="aimg_aRJgi" onclick="zoom(this)" onmouseover="img_onmouseoverfunc(this)" style="cursor:pointer" width="800"/)

1000037964.jpg
(58.23 KB, 下载次数: 4)

下载附件

2024-12-22 12:57 上传

<img src="https://img.saraba1st.com/forum/202412/22/125714qnht3ta3xcvrgaxm.jpg" referrerpolicy="no-referrer">

*****

####  李少卿  
##### 2#       发表于 2024-12-22 12:58

据说数学能力突飞猛进

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.1.88.3

*****

####  AshPenguin  
##### 3#       发表于 2024-12-22 13:00

但我不得不说一句 4o比o1-preview好用，所以这个o3能不能直接转换成生产力得试试才知道

*****

####  Jet.Black  
##### 4#       发表于 2024-12-22 13:03

为啥最近几天各路懂哥都说OpenAI药丸？还说谷歌已经无敌了。

*****

####  asion617  
##### 5#       发表于 2024-12-22 13:03

这价格短时内跟我们一般plus订阅也没啥关系了

*****

####  泰坦失足  
##### 6#       发表于 2024-12-22 13:05

to 广大科研人员：

这是lab的4090，现在快用它来战胜o3吧。

*****

####  泰坦失足  
##### 7#       发表于 2024-12-22 13:07

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=66987113&amp;ptid=2215654" target="_blank">Jet.Black 发表于 2024-12-22 13:03</a>

为啥最近几天各路懂哥都说OpenAI药丸？还说谷歌已经无敌了。</blockquote>
谷歌在OpenAI的几个领域：视频生成，长推理模型，多模态模型上都赶上了OpenAI吧。和过去的GPT4时代，幽默Gemini才到GPT3.5水平有很大差距。

当然还有盘古大模型5.0....至少序号上比GPT4/O3大

*****

####  juluck000  
##### 8#       发表于 2024-12-22 13:08

A社c模聊擦边已经废了，赶紧来个代餐吧

*****

####  UNICORN00  
##### 9#       发表于 2024-12-22 13:45

成本绷不住了吧

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.92

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| 偽物| + 1|好评加鹅|

查看全部评分

*****

####  yanjunle  
##### 10#       发表于 2024-12-22 15:53

怎么不贴最哈人的swebench71.7%？提10个issue能修7个已经达到一般码农水平了吧，就看推理成本下降多快了。按arc-agi那边的说法，做一道题要14分钟3500刀，比码农贵太多了。

阿里预告说千问明年赶上，可惜按照qwq32b做题时动不动把自己绕进去用掉一两万token的表现看，正经修bug可能也要用几亿甚至几十亿token，推理成本还是降不下来。

*****

####  Nanachi  
##### 11#       发表于 2024-12-22 16:00

四千美刀能回答宇宙的终极答案，就算是死也值回票价呀！

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.92

*****

####  张元英  
##### 12#       发表于 2024-12-22 16:08

sora吹半天拉了坨大的, 被打过脸的哪还敢轻信openai的营销了, 有些人已经开始喊openai天下第一营销了

*****

####  宏.  
##### 13#       发表于 2024-12-22 16:12

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=66987113&amp;ptid=2215654" target="_blank">Jet.Black 发表于 2024-12-22 13:03</a>

为啥最近几天各路懂哥都说OpenAI药丸？还说谷歌已经无敌了。</blockquote>
WSJ的消息是烧了10亿美元之后效果不如预期，这就说明基础假设就让人怀疑了
 <blockquote>OpenAI 的新人工智能项目进度落后，而且花费巨大。尚不清楚它何时或是否会成功。世界上可能没有足够的数据让它变得足够聪明。 

该项目正式名称为 GPT-5，代号为 Orion，已筹备了 18 个多月，旨在成为 ChatGPT 技术的重大进步。知情人士称，OpenAI 最亲密的合作伙伴和最大的投资者微软原本预计将在 2024 年中期左右看到新模型。

OpenAI 已经进行了至少两次大规模训练，每次训练都需要数月时间处理大量数据，目的是让 Orion 变得更智能。据了解该项目的人士称，每次训练都会出现新问题，软件无法达到研究人员所期望的结果。

他们表示，Orion 的表现充其量比 OpenAI 目前的产品要好，但还不足以证明维持新模型运行的巨大成本是合理的。根据公共和私人对训练各个方面的估计，为期六个月的训练运行仅在计算成本方面就可能花费约 5 亿美元。 </blockquote>

*****

####  铃森冬  
##### 14#       发表于 2024-12-22 16:37

力大砖飞式的工作，主要价值在于给投资人和围观群众展示 o1 的方法堆推理时间上限真的很高

不过话说回来推理成本降下去只是时间问题，保守估计两年降两个数量级肯定就比用人便宜了，以及说 AI 在某些任务上就是不行的可以闭嘴了

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.92

*****

####  依然荏苒  
##### 15#       发表于 2024-12-22 16:44

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=66988045&amp;ptid=2215654" target="_blank">张元英 发表于 2024-12-22 16:08</a>
sora吹半天拉了坨大的, 被打过脸的哪还敢轻信openai的营销了, 有些人已经开始喊openai天下第一营销了 ...</blockquote>
gpt如果是天下第一营销，那那些对标的算什么？

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.2.91

*****

####  zack2012  
##### 16#       发表于 2024-12-22 17:09

有sora这个造假先例在，openai的东西还是先观望吧

*****

####  撸一记  
##### 17#       发表于 2024-12-22 17:15

本来openAI就是典型大力出奇迹，现在力竭了，建议学阿诺多扎几针

*****

####  tillnight  
##### 18#       发表于 2024-12-22 17:16

裹挟全人类走上生成式人工智能这条可能完全歪了的AI道路当然不叫营销。实现AGI本来就有多种猜测和假想，在gpt之后只有一种了，确实不叫营销。

*****

####  StarForceTi  
##### 19#       发表于 2024-12-22 17:34

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=66987113&amp;ptid=2215654" target="_blank">Jet.Black 发表于 2024-12-22 13:03</a>

为啥最近几天各路懂哥都说OpenAI药丸？还说谷歌已经无敌了。</blockquote>
谷歌免费的小模型就能有openai付费订阅的4o的水平，速度和延迟还更好

*****

####  mrkikokiko  
##### 20#       发表于 2024-12-22 17:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=66987113&amp;ptid=2215654" target="_blank">Jet.Black 发表于 2024-12-22 13:03</a>

为啥最近几天各路懂哥都说OpenAI药丸？还说谷歌已经无敌了。</blockquote>
因为openai的领先越来越小，有些部分被反超，免费的开源模型能力也在接近，如果不能保持技术上的壁垒，那么openai凭什么以后能取得商业上的成功呢

*****

####  mimighost  
##### 21#       发表于 2024-12-22 18:41

o3看来他们大力搞出了另一个路子

是不是agi不知道，但是做题已经超过99.9%的人类了

*****

####  戏谑二次元  
##### 22#       发表于 2024-12-22 18:43

资本市场对o3的反应怎么样？

*****

####  瓦格雷  
##### 23#       发表于 2024-12-22 18:44

<blockquote>Nanachi 发表于 2024-12-22 16:00
四千美刀能回答宇宙的终极答案，就算是死也值回票价呀！

—— 来自 鹅球 v3.3.92 ...</blockquote>
我只要2000刀  而且先给你答案  42

记得打钱

*****

####  Fuero  
##### 24#       发表于 2024-12-22 18:53

pro订阅中，无限用o1还是爽的，不过再涨价就没啥心思续了<img src="https://static.saraba1st.com/image/smiley/face2017/018.png" referrerpolicy="no-referrer">

*****

####  双刀少女  
##### 25#       发表于 2024-12-22 19:00

码农朋友都在传这个，<img src="https://static.saraba1st.com/image/smiley/face2017/004.gif" referrerpolicy="no-referrer">还是很好奇它的实际工程能力

*****

####  子虚乌有  
##### 26#       发表于 2024-12-22 19:04

就一个劲吹呗

*****

####  御坂MKII  
##### 27#       发表于 2024-12-22 19:11

cf 2727 蒙谁呢<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

*****

####  Prolun  
##### 28#       发表于 2024-12-22 19:45

cf2727的确强

*****

####  jeokeo  
##### 29#       发表于 2024-12-22 20:34

借地问问有没有办法给gpt充值？我喜欢用api按量扣费，不喜欢包月。

*****

####  吴怀在  
##### 30#       发表于 2024-12-22 20:41

 本帖最后由 吴怀在 于 2024-12-22 20:43 编辑 

开源模型才是未来<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

我就等个本地的视频模型了，我要在听萌萌二次元歌曲MV时能完成下一首MV的自动剪辑。

迟早的事，老黄不做人也会有其他家搞的<img src="https://static.saraba1st.com/image/smiley/face2017/066.png" referrerpolicy="no-referrer">

*****

####  alixsander  
##### 31#         楼主| 发表于 2024-12-22 21:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=66989535&amp;ptid=2215654" target="_blank">吴怀在 发表于 2024-12-22 20:41</a>

开源模型才是未来

我就等个本地的视频模型了，我要在听萌萌二次元歌曲MV时能完成下一首MV的自动剪辑。</blockquote>
不是有hunyuan了么

*****

####  猫屎盆子  
##### 32#       发表于 2024-12-22 21:24

利好我们这种出事要背锅的岗位，AI永远不可能替人坐牢<img src="https://static.saraba1st.com/image/smiley/face2017/048.png" referrerpolicy="no-referrer">

*****

####  無始無終  
##### 33#       发表于 2024-12-23 07:56

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=66987113&amp;ptid=2215654" target="_blank">Jet.Black 发表于 2024-12-22 13:03</a>
为啥最近几天各路懂哥都说OpenAI药丸？还说谷歌已经无敌了。</blockquote>
因为谷歌爷爷真的做到了用小模型打掉OpenAI大模型

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  痴货  
##### 34#       发表于 2024-12-23 09:03

<img src="https://static.saraba1st.com/image/smiley/face2017/018.png" referrerpolicy="no-referrer"> 目前推动的所谓AGI就是个很矛盾的概念。不同于工业革命，如果达成了的话导致大部分人工生产力被替代，大量人失业，这些打工人同时又是重要的消费者，消费需求肯定会一蹶不振，那么那些主推部署AI的公司的营业额从哪里获取，难不成都跑步进入计划经济了？

前不久Ilyad的演讲就提到了目前AI预训练碰到的天花板就是数据不够用了，除非另辟蹊径自动产生大量高质量的数据，但这个本身就是有些类似鸡和蛋哪个先有的问题。如果已经能够自动生成大量的高质量数据，那么生产数据的算法或者模型岂不是已经具有了AGI？

*****

####  泰坦失足  
##### 35#       发表于 2024-12-23 09:41

“2022年是AI最难的一年。

那一年风头最旺的Deepmind，AI2，都稳稳压OpenAI一头，那个年代像OpenAI的公司有十几个。

湾区搞deep learning的startup基本在疫情闪崩后死了一大半，根本融不到钱，当时A16z和红杉的钱，全都在币圈的NFT小图片、DAO、各种DeFi等五花八门的项目里。

OpenAI当时几乎快死了， GPT-3出来的时候，几乎没人看，也并不开放使用。

那天我记得很清楚，在Github上面，GPT-3是第一名，而你党哥也第一次上了github trending，排名第四，那时候我还用的是《请回答1988》里成德善的头像。

那一年，人民币基金全都在等着快手、滴滴等等一批互联网公司全球上市，解锁套现，而国产AI的四小龙、地平线、寒武纪等等当时被认为吊打OpenAI，一个个摩拳擦掌，等着代表中国商业力量IPO。

那一年，中美半导体制裁，孟晚舟一个人把华为拖入深渊，搞得国内各政府主导基金像应激一样all in大炼芯片，加上去年石破天惊拿到了8万亿土地出让金，国内各省市像下饺子一样大造AI芯片，而大洋彼岸，大傻逼Intel收购了Nervana和Harbana，跟Xilinx收购深鉴科技一样，成了冤大头。

那一年，北美一大批教授们都在融资搞mlsys，ml infra，一个个开源各种库，把pytorch封装了一遍又一遍，打算做成toB的业务，卖给未来人。

那一年，另一批华人教授们坐飞机回国，开始趁着AI浪潮立山头，无论搞optimization的还是搞baysian的，摇身一变，全都成了深度学习泰斗，成了北京、上海、深圳政府和国资委的座上宾，招兵买马，全国各地AI研究院如雨后春笋一般挂牌成立，高薪聘请工程师，继续大灌水。

那一年，搞imagen和GPT/bert路线的人，都跟孙子似的，在全世界融不到钱，被那些做federated learning（联邦学习）、causal inference（因果推断）、AI Ethics（AI伦理）、土味商业分析、手搭神经网络的各种牛鬼蛇神在VC市场里打得找不着北——VC们根本不相信，也想象不到stable diffusion和ChatGPT会诞生出来。

那一年，人们看OpenAI，就像看个小丑一样，人们都在看GPT-3如何被Google T5吊打，拿DALLE paper当作废纸。

那一年，是AI的至暗时刻。”

不走大模型这条路走啥呢，那些Task你一个Task训练一个模型，一个领域出一个ResNet？当时还有个很火的AUTO ML自动调参，现在也早没人说了.

*****

####  泰坦失足  
##### 36#       发表于 2024-12-23 09:47

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=66994622&amp;ptid=2215654" target="_blank">痴货 发表于 2024-12-23 09:03</a>

目前推动的所谓AGI就是个很矛盾的概念。不同于工业革命，如果达成了的话导致大部分人工生产力被替代，大量 ...</blockquote>
AGI我看不知道啥时候才能出。但是推动Zeroshot/Fewshots就能完成任务的通用人形机器人，感觉有戏。比如最简单的做个鸡蛋灌饼，可能未来就是我演示下怎么做, 机器人就会做了。考虑到LLM现在还有几率发疯，重要岗位肯定还得是人，但是出点岔子也没事的地方就能用机器人了，可能是一个人类监督5到10个机器人，及时阻止出错的机器人。人形的好处是在各个领域都能用，以及淘汰的旧款能随便卖给别人。

*****

####  空気力学  
##### 37#       发表于 2024-12-23 09:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=66994910&amp;ptid=2215654" target="_blank">泰坦失足 发表于 2024-12-23 09:41</a>
“2022年是AI最难的一年。

那一年风头最旺的Deepmind，AI2，都稳稳压OpenAI一头，那个年代像OpenAI的公司有 ...</blockquote>
说到底大语言模型也就革了NLP的命，把高级中文屋子吹成AGI的路已经要到头了<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">

*****

####  alixsander  
##### 38#         楼主| 发表于 2024-12-23 10:13

<blockquote>空気力学 发表于 2024-12-23 09:51
说到底大语言模型也就革了NLP的命，把高级中文屋子吹成AGI的路已经要到头了 ...</blockquote>
中文房间这种古早思辨根本没有价值

姑且不论不可能存在无限的LOOK UP TABLE给每个问题列出答案（换句话说LLM根本不是这么实现的，LLM本身是实现了对语言的建模，自回归只是实现模型输出的形式，而不是对训练集的重复）

如果有一个许愿机，能给你的每个问题都输出答案，那它就是全知全能的，和它的实现形式没有关系

*****

####  空気力学  
##### 39#       发表于 2024-12-23 12:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=66995173&amp;ptid=2215654" target="_blank">alixsander 发表于 2024-12-23 10:13</a>
中文房间这种古早思辨根本没有价值

姑且不论不可能存在无限的LOOK UP TABLE给每个问题列出答案（换句话 ...</blockquote>
你说的对，但是大语言模型（和语言）也就是中文屋式的局部索引和查表输出。这个输出无法实现熵减，完全没法支持大模型实现自举，所以Closed AI才说训练材料不够了。

*****

####  alixsander  
##### 40#         楼主| 发表于 2024-12-23 15:46

 本帖最后由 alixsander 于 2024-12-23 15:51 编辑 
<blockquote>空気力学 发表于 2024-12-23 12:27
你说的对，但是大语言模型（和语言）也就是中文屋式的局部索引和查表输出。这个输出无法实现熵减，完全没 ...</blockquote>

迷惑发言：

1.熵减是热力学系统概念，越有序熵越低。信息熵定义不一样，信息越有价值信息熵越高，为什么要熵减？

2.当然可以自举，当前已经大量使用合成语料，大模型训小模型进行预训练了。预训练到头是ILYA说的，meta和OAI并不同意。

3.自然语言和LLM都不是词表映射。这几乎是不证自明的。1B模型就能正常说话，查找表能那么小？

现在还认为LLM是表象的next token prediction也太迟钝了，除非你说你没关心这块的发展。

就像LeCun之前认为的，LLM一定无药可救，因为仅仅是自回归猜字必然导致累积误差随输出增长而增大，必然导致长输出胡言乱语。

然而实际上呢，推理时越大（而且只是单纯的接字没有MCTS之类的东西）性能和洞察力越强，说明自回归只是输出它内在建模的手段而已，已经是不证自明的了


*****

####  mimighost  
##### 41#       发表于 2024-12-23 16:36

搞思想实验一点儿意思都没有

ai现在就像是38年的核裂变，实验成功了，能做成啥，谁都没数。当年海森堡那系的人打死都不相信美国人能把核弹小型化成功

ai现在就是这种状况。o3的推理能力，在benchmark上已经远超人类，但是实际上要产生工程价值还远。o3出来我思考了很长时间，我觉得目前的问题在于，整个人类软件工程的实践和目前的ai能力并不匹配，如果软工的认知不更新，强行引入ai会产生一些可笑的结果的。比如我知道的一个项目就是试图用ai来写单元测试，后来那些码农无脑通过ai写的代码，非但没有增加代码的健壮性，反而引入一大堆一知半解的垃圾代码，被上面狠批了一顿。

当然这不是唱衰ai，ai成为写码的主力的那一天，我觉得已经是注定会到来。到时候怎么让人类来插入这个流程就是一个很有价值的问题了。

软件行业面临大洗牌，终于感受到当年学长给我说的干到老学到老，这行的经验真不值钱


*****

####  wqm2008  
##### 42#       发表于 2024-12-23 16:55

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=66988262&amp;ptid=2215654" target="_blank">铃森冬 发表于 2024-12-22 16:37</a>

力大砖飞式的工作，主要价值在于给投资人和围观群众展示 o1 的方法堆推理时间上限真的很高

不过话说回来推 ...</blockquote>
AI4S这块先搓出一个商业化的FIC出来再说某些任务上行，所有AI+drugs，晶泰智峪星药深势还是海外的Exscientia纯纯cjb，建议不要贷款cjb


*****

####  空気力学  
##### 43#       发表于 2024-12-23 19:26

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=66997832&amp;ptid=2215654" target="_blank">alixsander 发表于 2024-12-23 15:46</a>
迷惑发言：

1.熵减是热力学系统概念，越有序熵越低。信息熵定义不一样，信息越有价值信息熵越高，为什么 ...</blockquote>
说得不够清楚是我的错。
&gt; 1.熵减是热力学系统概念，越有序熵越低。信息熵定义不一样，信息越有价值信息熵越高，为什么要熵减？

信息越丰富则信息熵越高，例如均匀分布的熵就比狄拉克分布要高。LLM作为生成模型可以产生很丰富的信息是没错，但是问题在于LLM本身无法像人一样从中提取出“正确”的信息。从丰富的假设中找到正确的答案就是“熵减”的过程。就现在的结果来看，LLM确实具有语言智能，但是它并不能学会严谨的逻辑推理和计算，它所做的一切都是在语言上模仿训练集中存在的逻辑规律，而非真正地进行逻辑分析。

&gt; 2.当然可以自举，当前已经大量使用合成语料，大模型训小模型进行预训练了。预训练到头是ILYA说的，meta和OAI并不同意。

用GPT-4o生成的语料可以提升小模型的性能不假，但它能训练出和GPT-4o同等的LLM吗？之前已经有论文尝试用LLM自己生成训练语料来尝试自举，结果是模型的输出很快坍缩到少量固定的模式中。GPT4o生成的语料要是能支持它自举，也不会有Closed AI说训练语料不够用的传闻了。说到底，LLM还是需要依赖外部智能的输入来筛选生成语料中的有用信息，实现“熵减”。

&gt; 3.自然语言和LLM都不是词表映射。这几乎是不证自明的。1B模型就能正常说话，查找表能那么小？现在还认为LLM是表象的next token prediction也太迟钝了，除非你说你没关心这块的发展。

我不是说LLM是简单的词表映射，实际发生的是发生在某些连续的latent space的相关性映射。语言的规律和基础逻辑就蕴含在这样的映射中。LLM确实具有很好的语言能力，但是这种能力只是AGI想要的智能所包含的一个子集。

&gt; 就像LeCun之前认为的，LLM一定无药可救，因为仅仅是自回归猜字必然导致累积误差随输出增长而增大，必然导致长输出胡言乱语。然而实际上呢，推理时越大（而且只是单纯的接字没有MCTS之类的东西）性能和洞察力越强，说明自回归只是输出它…

我也没有说LLM只是简单的regression model。显然魔法主要发生在预训练后的RLHF。更多的模型参数显然可以让模型学到更多蕴含在语料中的token相关性以及人类反馈评价中包含的推理和逻辑能力，但是这也不能证明LLM具有除了语言能力之外通向AGI需要的全部智能。事实就是现在依然没有LLM可以在数学计算上达到经过训练的人类一样的可靠性。LLM表现出来的智能仍然是基于regression的模仿而不是主动、严谨的逻辑思考。

要实现AGI显然需要LLM框架以外的新模型和方法。


*****

####  素盏鸣尊  
##### 44#       发表于 2024-12-24 07:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=66994622&amp;ptid=2215654" target="_blank">痴货 发表于 2024-12-23 09:03</a>

目前推动的所谓AGI就是个很矛盾的概念。不同于工业革命，如果达成了的话导致大部分人工生产力被替代，大量 ...</blockquote>
ilya算个吊。被金闪闪秒的货，这事还得听论坛砖家@月珊瑚与紫鸢尾的。三个月前信誓旦旦告诉我数据和化石能源一样一百年内都不会枯竭。

