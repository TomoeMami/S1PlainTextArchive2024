
*****

####  overflowal  
##### 1#       楼主       发表于 2024-12-27 10:12

[https://mp.weixin.qq.com/s/iFZOQsUNkpkXPDvOkE99wQ](https://mp.weixin.qq.com/s/iFZOQsUNkpkXPDvOkE99wQ)

总结：超过600B参数的MoE模型，在各种测试中和sonnet媲美，不少测试中都超过了sonnet和4o。推理速度大幅度提升

X上讨论的热火朝天，不仅仅是因为这是第一个真正达到闭源商业模型水平的开源模型，
<strong>还有他们只用了2000块H800，训练了两个月，大概550万美金的训练成本</strong>，和友商动辄上亿的训练成本相比显得友商非常小丑

同时api的费用就算涨价了也远远低于友商。

*****

####  Lillia  
##### 2#       发表于 2024-12-27 10:15

这也太牛逼了只花550W，3.5sonnet的文字处理能力已经非常强了

*****

####  qratosones1337  
##### 3#       发表于 2024-12-27 10:16

土五老师说的没错，美国就是人种不行，不然你无法解释Meta和XAI花了那么多钱屯了那么多卡，最后都干啥了

﹍﹍﹍

评分

 参与人数 2战斗力 0

|昵称|战斗力|理由|
|----|---|---|
| bgod666| + 1|要扣去扣土星五号|
| RandomDictator|-1|直接人种也是有点好笑了|

查看全部评分

*****

####  hencechen  
##### 4#       发表于 2024-12-27 10:17

 本帖最后由 hencechen 于 2024-12-27 10:23 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67032000&amp;ptid=2224601" target="_blank">qratosones1337 发表于 2024-12-27 10:16</a>

土五老师说的没错，美国就是人种不行，不然你无法解释Meta和XAI花了那么多钱屯了那么多卡，最后都干啥了 ...</blockquote>
meta新出来的Llama那个版本还可以。我觉得现在有种’大模型倦怠“。大家数据指标上都在刷新刷新，今天你长文本解读能力提高15%，明天我在aime上可以拿高分……看上去你好我也好，但是真部署起来开始推理，又感觉都差球不多，拉不开档次的差距。<img src="https://static.saraba1st.com/image/smiley/face2017/001.png">

感觉就像功能机时代的手机，诺基亚爱立信moto今天你出一款，明天我出一款，反正都是你提高了续航、我提高了喇叭音量，竞争了3、5年回头一看，还是那个鸟样……亟需要一款iPhone级别的产品来降维打击，真正”教育“市场，可惜现在看起来最有希望的chatGPT也没做到<img src="https://static.saraba1st.com/image/smiley/face2017/001.png" referrerpolicy="no-referrer">

*****

####  qratosones1337  
##### 5#       发表于 2024-12-27 10:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67032016&amp;ptid=2224601" target="_blank">hencechen 发表于 2024-12-27 10:17</a>

meta新出来的Llama那个版本还可以。我觉得现在有种’大模型倦怠“。大家数据指标上都在刷新刷新，看上去你 ...</blockquote>
Meta的卡是阿里的五到六倍，然后LLama现在也就是个跟Qwen有来有回的水平，长链推理方面也没啥动静

*****

####  中国人  
##### 6#       发表于 2024-12-27 10:21

幻方主业还是搞量化交易的<img src="https://static.saraba1st.com/image/smiley/face2017/034.png" referrerpolicy="no-referrer">

*****

####  qratosones1337  
##### 7#       发表于 2024-12-27 10:29

另外这次首发上了NPU推理，看来DeepSeek现在也是华为KA客户了

*****

####  泰坦失足  
##### 8#       发表于 2024-12-27 10:30

Sonnet不是已经被自己啥Haiku超越了吗。看了下就是比Qwen 2.5 72b强些的水平（但是400b）。现在最需要的还是一个能自我反思的长思考树的模型，类似 O1 Pro mode, 但是准确性需要提升。

前略，消失的盘古大模型5.0 <img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  qratosones1337  
##### 9#       发表于 2024-12-27 10:34

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67032181&amp;ptid=2224601" target="_blank">泰坦失足 发表于 2024-12-27 10:30</a>

Sonnet不是已经被自己啥Haiku超越了吗。看了下就是比Qwen 2.5 72b强些的水平（但是400b）。现在最需要的还 ...</blockquote>
你搞反了吧，Haiku是小号模型，Sonnet才是中号，现在A社对外提供服务的最好模型就是Sonnet 3.5

*****

####  Nanachi  
##### 10#       发表于 2024-12-27 10:38

一直在用DeepSeek的API搭配沉浸式翻译看外网文章

*****

####  泰坦失足  
##### 11#       发表于 2024-12-27 10:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67032235&amp;ptid=2224601" target="_blank">qratosones1337 发表于 2024-12-27 10:34</a>

你搞反了吧，Haiku是小号模型，Sonnet才是中号，现在A社对外提供服务的最好模型就是Sonnet 3.5 ...</blockquote>
在最终测试中，Haiku 在许多基准测试中超越了 Claude 3 Opus，我们之前的旗舰模型，成本却低得多，" Anthropic 在 X 上写道。"因此，我们提高了 Claude 3.5 Haiku 的定价，以反映其智能的提升。

记错了，Claude的命名比OpenAI还抽象<img src="https://static.saraba1st.com/image/smiley/face2017/252.png" referrerpolicy="no-referrer">

*****

####  無始無終  
##### 12#       发表于 2024-12-27 10:56

啥时候代码能力能恢复到V2.5 Coder的水平

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  overflowal  
##### 13#         楼主| 发表于 2024-12-27 11:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67032544&amp;ptid=2224601" target="_blank">無始無終 发表于 2024-12-27 10:56</a>

啥时候代码能力能恢复到V2.5 Coder的水平

—— 来自 S1Fun</blockquote>
恢复啥，这模型code能力很多benchmark比3.5 sonnet都强

*****

####  qratosones1337  
##### 14#       发表于 2024-12-27 11:05

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67032335&amp;ptid=2224601" target="_blank">泰坦失足 发表于 2024-12-27 10:41</a>

在最终测试中，Haiku 在许多基准测试中超越了 Claude 3 Opus，我们之前的旗舰模型，成本却低得多，" Anth ...</blockquote>
理论上Claude 3.5这一代还有超大杯，但现在没有对外开放，目前开放的最好的就是3.5 Sonnet

*****

####  weibo.com  
##### 15#       发表于 2024-12-27 11:07

幻方的人是不是浙大竺院派的？

*****

####  洛拉斯  
##### 16#       发表于 2024-12-27 11:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67032303&amp;ptid=2224601" target="_blank">Nanachi 发表于 2024-12-27 10:38</a>
一直在用DeepSeek的API搭配沉浸式翻译看外网文章</blockquote>
成本如何？

*****

####  qratosones1337  
##### 17#       发表于 2024-12-27 11:12

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67032717&amp;ptid=2224601" target="_blank">洛拉斯 发表于 2024-12-27 11:11</a>

成本如何？</blockquote>
GPT-4o的百分之一

DeepSeek最大的特点就是价格极其便宜

*****

####  迷路的石头  
##### 18#       发表于 2024-12-27 11:12

幻方这家神奇的公司，本来是做量化私募的，20年21年大牛市运营的基金效益非常好，老总就梭哈买了10000张A100搞人工智能量化，结果碰上熊市和算法过拟合大回撤，现在看清大A本质连中性策略也不做了。当初知乎都在笑话他们投资AI步子太大扯着蛋。

结果老登开始搞算力禁运后，这些卡瞬间成了香饽饽，现在转型人工智能服务商了

*****

####  qqq2142  
##### 19#       发表于 2024-12-27 11:13

但是deep价格翻倍了啊
我还指望跑小黄油呢

—— 来自 [鹅球](https://www.pgyer.com/xfPejhuq) v3.0.87-alpha

*****

####  Nanachi  
##### 20#       发表于 2024-12-27 11:13

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67032717&amp;ptid=2224601" target="_blank">洛拉斯 发表于 2024-12-27 11:11</a>

成本如何？</blockquote>
可用总余额

212.92 万

tokens

可用 tokens 根据最新输出价格预估

充值余额

¥4.25

CNY

约 212.92 万 tokens

赠送余额  查看有效期

¥0.00

CNY

0 token

本月消费

¥2.49

CNY

约 284.99 万 tokens

*****

####  迷路的石头  
##### 21#       发表于 2024-12-27 11:15

<blockquote>中国人 发表于 2024-12-27 10:21
幻方主业还是搞量化交易的</blockquote>
量化步子迈太大，参数过拟合，业绩回撤

结果又因为这个大步子，阴拆阳错手握了国内仅此于几个互联网大厂的算力，顺势转型AI

*****

####  迷路的石头  
##### 22#       发表于 2024-12-27 11:15

<blockquote>weibo.com 发表于 2024-12-27 11:07
幻方的人是不是浙大竺院派的？</blockquote>
浙大的很多

*****

####  gnihton314  
##### 23#       发表于 2024-12-27 11:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67032781&amp;ptid=2224601" target="_blank">迷路的石头 发表于 2024-12-27 11:15</a>

浙大的很多</blockquote>
不是很多，初创团队就是一帮浙大老同学攒的局

*****

####  mandown  
##### 24#       发表于 2024-12-27 11:25

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67032335&amp;ptid=2224601" target="_blank">泰坦失足 发表于 2024-12-27 10:41</a>

在最终测试中，Haiku 在许多基准测试中超越了 Claude 3 Opus，我们之前的旗舰模型，成本却低得多，" Anth ...</blockquote>
haiku是日语俳句的意思吗？

*****

####  ffail  
##### 25#       发表于 2024-12-27 11:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67032303&amp;ptid=2224601" target="_blank">Nanachi 发表于 2024-12-27 10:38</a>

一直在用DeepSeek的API搭配沉浸式翻译看外网文章</blockquote>
求分享具体教程

*****

####  UNICORN00  
##### 26#       发表于 2024-12-27 11:29

在用2.5，免费，还行吧

*****

####  闷吸  
##### 27#       发表于 2024-12-27 11:30

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67032068&amp;ptid=2224601" target="_blank">中国人 发表于 2024-12-27 10:21</a>

幻方主业还是搞量化交易的</blockquote>
充分说明深度学习在量化行业没有那么work<img src="https://static.saraba1st.com/image/smiley/face2017/029.png" referrerpolicy="no-referrer">

*****

####  Nanachi  
##### 28#       发表于 2024-12-27 11:33

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67032932&amp;ptid=2224601" target="_blank">ffail 发表于 2024-12-27 11:27</a>
求分享具体教程</blockquote>
DeepSeek | 沉浸式翻译
https://immersivetranslate.com/zh-Hans/docs/services/deepseek/

沉浸式翻译官方就有指南

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.3.92

*****

####  overflowal  
##### 29#         楼主| 发表于 2024-12-27 11:41

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67032717&amp;ptid=2224601" target="_blank">洛拉斯 发表于 2024-12-27 11:11</a>

成本如何？</blockquote>
百万token输入1元，输出2元。2月后涨价到输入2元，输出8元。考虑到这是3.5 sonnet级别的性能，简直是击穿底线的价格

*****

####  小野賢章  
##### 30#       发表于 2024-12-27 11:48

试了一下，被回答的速度震惊了<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  迷路的石头  
##### 31#       发表于 2024-12-27 11:49

<blockquote>闷吸 发表于 2024-12-27 11:30
充分说明深度学习在量化行业没有那么work</blockquote>
金融行业的数据信噪比极低，搞深度学习就是给模型喂噪音，出来一堆过拟合

*****

####  浅井惠  
##### 32#       发表于 2024-12-27 13:31

最重要的是不知道v3上线后还能不能继续用v2，目前主要用来翻译小黄油感觉其实v2已经够用了，玩得多一个月估计得用上千万token，成本一下就从30升到上百了

*****

####  紧那罗  
##### 33#       发表于 2024-12-27 13:48

借帖问一下现在ASR模型有什么比openai的whisper好用或者便宜的么

这两年llm感觉发展极快 价格也是猛降

语音识别还在用最老的whisper 价格也挺贵的<img src="https://static.saraba1st.com/image/smiley/face2017/044.png" referrerpolicy="no-referrer">

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| ichirukia1566| + 1|同问|

查看全部评分

*****

####  bl0ck  
##### 34#       发表于 2024-12-27 13:52

今年nips讨论很多的就是不止训练撞墙，推理也撞墙了，以后就是拼成本了

[论坛助手,iPhone](https://bbs.saraba1st.com/2b/forum.php?mod=viewthread&amp;tid=2029836)

*****

####  xibeijian  
##### 35#       发表于 2024-12-27 13:59

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67033077&amp;ptid=2224601" target="_blank">overflowal 发表于 2024-12-27 11:41</a>

百万token输入1元，输出2元。2月后涨价到输入2元，输出8元。考虑到这是3.5 sonnet级别的性能，简直是击穿 ...</blockquote>
本地使用 lmstudio + GGUF模型搞翻译，可以试试吧。如果显卡内存超过 12G的话。

*****

####  cfeng123  
##### 36#       发表于 2024-12-27 14:06

我一直用他们的本地模型，算是日常小助手，还挺好用的

*****

####  screeper  
##### 37#       发表于 2024-12-27 14:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67034198&amp;ptid=2224601" target="_blank">紧那罗 发表于 2024-12-27 13:48</a>
借帖问一下现在ASR模型有什么比openai的whisper好用或者便宜的么

这两年llm感觉发展极快 价格也是猛降

语音 ...</blockquote>
在本地跑faster-whisper，8G显存就能跑large-v3了，效果也很不错

*****

####  無始無終  
##### 38#       发表于 2024-12-27 14:16

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67032599&amp;ptid=2224601" target="_blank">overflowal 发表于 2024-12-27 11:01</a>

恢复啥，这模型code能力很多benchmark比3.5 sonnet都强</blockquote>
至少我看的知乎上那个评测人的题，V3的编程能力和V2.5持平，不如V2 Coder

*****

####  UncleDracula  
##### 39#       发表于 2024-12-27 21:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67032990&amp;ptid=2224601" target="_blank">Nanachi 发表于 2024-12-27 11:33</a>

DeepSeek | 沉浸式翻译

https://immersivetranslate.com/zh-Hans/docs/services/deepseek/</blockquote>
试了下翻译网页，速度很慢，同一个网页谷歌秒翻，请问是什么原因？

*****

####  洛拉斯  
##### 40#       发表于 2024-12-27 21:46

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67037622&amp;ptid=2224601" target="_blank">UncleDracula 发表于 2024-12-27 21:42</a>
试了下翻译网页，速度很慢，同一个网页谷歌秒翻，请问是什么原因？</blockquote>
因为服务器ai翻译服务器响应本来就慢

谷歌块那是机翻


*****

####  Van夫膜开  
##### 41#       发表于 2024-12-27 22:10

看看同期的清华，字节的发展。

这群论文制霸学阀和“顶级”高校弟子组成的论文大神专业队伍，做出来的模型，真的是一言难尽，纯纯浪费电力。

幻方能从一堆论文天才和顶会霸王导师里面选了纯国产的几位大牛搞出deepseek这个模型，这个眼光是真没得说。

*****

####  UncleDracula  
##### 42#       发表于 2024-12-27 22:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67037641&amp;ptid=2224601" target="_blank">洛拉斯 发表于 2024-12-27 21:46</a>

因为服务器ai翻译服务器响应本来就慢

谷歌块那是机翻</blockquote>
懂了，感谢


*****

####  凉良  
##### 43#       发表于 2024-12-27 22:16

试用了下翻译  玩了会酒馆 感觉不错


*****

####  行星减速器MK2  
##### 44#       发表于 2024-12-27 22:51

用来给酒馆和日用coder的，酒馆温度高点用个好预设真打平克劳德，而且价格低所以roll完全不心疼

—— 来自 [S1Fun](https://s1fun.koalcat.com)

*****

####  大阪黑鸡  
##### 45#       发表于 2024-12-27 22:53

现在最烂的是腾讯吧。

*****

####  takitaki  
##### 46#       发表于 2024-12-27 22:53

自带的"深度思考"反而会让ai变成不听人话的智障，不过真的很好用。

*****

####  overflowal  
##### 47#         楼主| 发表于 2024-12-27 22:54

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67038046&amp;ptid=2224601" target="_blank">takitaki 发表于 2024-12-27 22:53</a>
自带的"深度思考"反而会让ai变成不听人话的智障，不过真的很好用。</blockquote>
深度思考是另一个模型在回答，r1-lite

—— 来自 Xiaomi 23049RAD8C, Android 14上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.5.2-play

*****

####  陈八尺  
##### 48#       发表于 2024-12-27 22:55

这价格涨得有点猛啊，看来要提前多充点。


*****

####  kouym  
##### 49#       发表于 2024-12-27 23:01

之前是真便宜 看了眼就算涨价了还是很便宜


*****

####  kouym  
##### 50#       发表于 2024-12-27 23:05

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=67034067&amp;ptid=2224601" target="_blank">浅井惠 发表于 2024-12-27 13:31</a>

最重要的是不知道v3上线后还能不能继续用v2，目前主要用来翻译小黄油感觉其实v2已经够用了，玩得多一个月估 ...</blockquote>
看公告今天已经换v3了 应该是没有v2对外的接口了

原来黄油这么大的文字量吗

*****

####  笨拙的机器人  
##### 51#       发表于 2024-12-27 23:06

<blockquote>闷吸 发表于 2024-12-27 11:30
充分说明深度学习在量化行业没有那么work</blockquote>
 因为股价不太是一个自回归系统，用transformer直接预测next token从建模角度是不合理的。用无监督范式呢，建模方式倒是合理了，但是样本量需求量更大，要大好几个数量级才能训出来，也不容易啦


*****

####  Rachalgepa  
##### 52#       发表于 2024-12-28 00:35

宣传上有功夫，meta当时有成熟的fp8驱动吗？好意思跟人家比训练时间。


*****

####  kozalak  
##### 53#       发表于 2024-12-28 00:50

有大佬测过翻译和4o比差别大吗

—— 来自 [鹅球](https://www.pgyer.com/GcUxKd4w) v3.1.88.3

