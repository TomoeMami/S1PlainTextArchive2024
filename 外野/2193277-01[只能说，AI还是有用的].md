
*****

####  4396777  
##### 1#       楼主       发表于 2024-7-30 10:44

以前没有AI的时候，写一篇写新闻稿可能需要十分钟，但是你可以借着思考文章编排的由头，正大光明地摸个一个半个小时，现在有了生成式AI，一两分钟就能出稿，结果剩下的时间摸鱼就开始变得畏畏缩缩了，尤其是身边的同事在到处走动的情况下<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">

*****

####  神必迷你龙  
##### 2#       发表于 2024-7-30 10:51

推荐一个能写的ai，现在用的kimi，总感觉差点意思，难道是我用的方式不对？

*****

####  4396777  
##### 3#         楼主| 发表于 2024-7-30 10:52

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65741645&amp;ptid=2193277" target="_blank">神必迷你龙 发表于 2024-7-30 10:51</a>

推荐一个能写的ai，现在用的kimi，总感觉差点意思，难道是我用的方式不对？ ...</blockquote>
就写一点私企所在行业的行业新闻，我都是直接文心的，不搞那么麻烦的东西

*****

####  逆天的小鼠人  
##### 4#       发表于 2024-7-30 10:54

是的，对于重复性文书工作，即使是7B小模型也可以做得很好，反正最后都要读一遍

目前我比较担心的是，目前大模型进一步 scale up 还有意义吗？除了码农真的有人能感觉到模型规模增大的效果吗？最后老黄的那堆计算卡，会不会类似于矿难那一波一样，到时候整个 AI 市场像雪崩一样，整个市场和互联网第一次泡沫前非常类似，资本过于集中，而盈利方式又不明确

*****

####  7776169  
##### 5#       发表于 2024-7-30 10:55

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65741687&amp;ptid=2193277" target="_blank">逆天的小鼠人 发表于 2024-7-30 10:54</a>
是的，对于重复性文书工作，即使是7B小模型也可以做得很好，反正最后都要读一遍

目前我比较担心的是，目前 ...</blockquote>
到时候我觉得老黄他们又会换个东西吹<img src="https://static.saraba1st.com/image/smiley/face2017/019.png" referrerpolicy="no-referrer">

—— 来自 OnePlus GM1900, Android 10上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v3.0.0.81-alpha

*****

####  phoenixxj  
##### 6#       发表于 2024-7-30 11:01

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65741687&amp;ptid=2193277" target="_blank">逆天的小鼠人 发表于 2024-7-30 10:54</a>

是的，对于重复性文书工作，即使是7B小模型也可以做得很好，反正最后都要读一遍

目前我比较担心的是，目前 ...</blockquote>
高端it行业不清楚或者不想或者不敢涉及更深层次的社科类工作

比如律师 专利代理人 金融等等

或者很多看似重复性的工作，实际服务收费相当昂贵。

所以ai想要赚钱，目前最好的方式是普世化，就像互联网一样。但是这个过程很漫长，也有很多阻挠，甚至还有前车之鉴。

我现在的工作就是蹭了ai的便利，上次去开行业研讨会，发现大家其实根本不知道ai，但是也有几个发现这个套路。

*****

####  神必迷你龙  
##### 7#       发表于 2024-7-30 11:04

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65741658&amp;ptid=2193277" target="_blank">4396777 发表于 2024-7-30 10:52</a>

就写一点私企所在行业的行业新闻，我都是直接文心的，不搞那么麻烦的东西 ...</blockquote>
那我试试文心，谢谢分享

*****

####  电话微波炉  
##### 8#       发表于 2024-7-30 11:05

以前的老东西用Excel或者vba自动化办公，大概就是你现在这种心态吧

*****

####  隐形术的隐形书  
##### 9#       发表于 2024-7-30 11:10

生活离不开ai了，任何文书全部都用ai，做任何事前问问ai有什么要注意的

甚至打电话我都先用ai过一遍有礼貌的措辞，

人类只需要提供思想，剩下的表达交给ai

*****

####  ZekNagPul  
##### 10#       发表于 2024-7-30 11:11

 本帖最后由 ZekNagPul 于 2024-7-30 11:13 编辑 
<blockquote>逆天的小鼠人 发表于 2024-7-30 10:54
是的，对于重复性文书工作，即使是7B小模型也可以做得很好，反正最后都要读一遍

目前我比较担心的是，目前 ...</blockquote>

兄逮，7B是从基础模型蒸馏和剪枝出来的

要是没有训练几百B的大模型，7B是纯脑瘫

scaling law目前还是有效，估计下一个涌现节点是100万亿（大脑皮层神经元连接数）

*****

####  小妻水亚美  
##### 11#       发表于 2024-7-30 11:11

提示: 作者被禁止或删除 内容自动屏蔽

*****

####  逆天的小鼠人  
##### 12#       发表于 2024-7-30 11:17

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65741899&amp;ptid=2193277" target="_blank">ZekNagPul 发表于 2024-7-30 11:11</a>

兄逮，7B是从基础模型蒸馏和剪枝出来的

要是没有训练几百B的大模型，7B是纯脑瘫

scaling law目前还是有效 ...</blockquote>
我不相信存在涌现这个现象

我更加偏向于涌现的表象是人类对于AI智能水平的评价并非线性的结果

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| 我是大鲨鱼1453| + 1|一语中的|

查看全部评分

*****

####  右代宫嘉音  
##### 13#       发表于 2024-7-30 11:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65741687&amp;ptid=2193277" target="_blank"> 逆天的小鼠人 发表于 2024-7-30 10:54</a> 是的，对于重复性文书工作，即使是7B小模型也可以做得很好，反正最后都要读一遍  目前我比较担心的是，目前大模型进一步 scale up 还有意义吗？除了码农真的有人能感觉到模型规模增大的效果吗？最后老黄的那堆计算卡，会不会类似于矿难那一波一样，到时候整个 AI 市场像雪崩一样，整个市场和互联网第一次泡沫前非常类似，资本过于集中，而盈利方式又不明确 </blockquote>
现在gpt4o写代码能力真的牛逼，我十几年码农通过这个大幅度提升工作效率。当然现在我手下完全无法像我一样提升效率，因为gpt在专业领域的代码需要专业的提示，提示越专业它越强。来自: iPhone客户端

*****

####  玉米黍  
##### 14#       发表于 2024-7-30 11:40

可以预见未来网络上和大街上都会充斥着AI提供的无实际意义的信息内容。<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

*****

####  Nanachi  
##### 15#       发表于 2024-7-30 11:42

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65741687&amp;ptid=2193277" target="_blank">逆天的小鼠人 发表于 2024-7-30 10:54</a>

是的，对于重复性文书工作，即使是7B小模型也可以做得很好，反正最后都要读一遍

目前我比较担心的是，目前 ...</blockquote>
有哪些可本地部署在办公电脑（GPU弱鸡）的小模型推荐吗？

*****

####  ZekNagPul  
##### 16#       发表于 2024-7-30 12:04

<blockquote>逆天的小鼠人 发表于 2024-7-30 11:17
我不相信存在涌现这个现象

我更加偏向于涌现的表象是人类对于AI智能水平的评价并非线性的结果 ...</blockquote>

涌现是一种广泛存在于复杂系统的特性，不局限于LLM

超导，相变这些物理现象都属于涌现。生命本质是一种自组织现象，也是涌现。神经元链接产生意识，几乎可以肯定意识和思维是一种涌现。

不用很复杂的模型，game of life就可以看到涌现现象

*****

####  乾理央  
##### 17#       发表于 2024-7-30 12:09

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65742248&amp;ptid=2193277" target="_blank">玉米黍 发表于 2024-7-30 11:40</a>
可以预见未来网络上和大街上都会充斥着AI提供的无实际意义的信息内容。</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">没事，现在也是充斥着人类提供的无实际意义的信息内容

*****

####  TiiTiiLL  
##### 18#       发表于 2024-7-30 12:14

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65742272&amp;ptid=2193277" target="_blank">Nanachi 发表于 2024-7-30 11:42</a>

有哪些可本地部署在办公电脑（GPU弱鸡）的小模型推荐吗？</blockquote>
办公需求比较高的话还是gpt-4o比较好，可以本地部署的开源小模型一般中文能力不太行，有些信息也不太全

*****

####  ParadiseMartyr  
##### 19#       发表于 2024-7-30 12:16

 本帖最后由 ParadiseMartyr 于 2024-7-30 12:23 编辑 

总有人觉得ai能代替律师和法官<img src="https://static.saraba1st.com/image/smiley/face2017/037.png" referrerpolicy="no-referrer">
也就能写个诉状了，而且都要填内容，不如直接诉状模板里自己填了。
想必是非常喜欢少数派报告和西拉比系统吧

—— 来自 Xiaomi 23054RA19C, Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v2.1.2

*****

####  lin2004  
##### 20#       发表于 2024-7-30 12:17

Ai这玩意如果成本（部署训练使用）下不来无法塞进手机或者个人电脑里离线玩，那最后只会成为得跟高铁一样的大型基础设施，盈利可能行，赚大钱基本就做梦了（

*****

####  宏  
##### 21#       发表于 2024-7-30 12:28

提示: 作者被禁止或删除 内容自动屏蔽

*****

####  lin2004  
##### 22#       发表于 2024-7-30 12:29

<blockquote>宏 发表于 2024-7-30 12:28
微信免费不代表腾讯不赚钱</blockquote>
也没说高铁不赚钱，性质从稀缺商品变成透明的基建而已。

*****

####  云卷花开  
##### 23#       发表于 2024-7-30 12:51

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65742505&amp;ptid=2193277" target="_blank">ZekNagPul 发表于 2024-7-30 12:04</a>
涌现是一种广泛存在于复杂系统的特性，不局限于LLM

超导，相变这些物理现象都属于涌现。生命本质是一种 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/009.gif" referrerpolicy="no-referrer">我不知道我想要啥，也不知道能得到啥，就硬堆堆规模看看我能拿到什么东西是吧
<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">智能这事人类连问题是什么都没摸到，怎么就能觉得能靠堆规模拿到啥靠谱的东西呢，这不守株待兔嘛

—— 来自 OnePlus PJD110, Android 14上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v3.0.0.81-alpha

*****

####  宏  
##### 24#       发表于 2024-7-30 12:56

提示: 作者被禁止或删除 内容自动屏蔽

*****

####  宏  
##### 25#       发表于 2024-7-30 12:58

提示: 作者被禁止或删除 内容自动屏蔽

*****

####  lukesweet  
##### 26#       发表于 2024-7-30 13:09

<blockquote>云卷花开 发表于 2024-7-30 12:51
我不知道我想要啥，也不知道能得到啥，就硬堆堆规模看看我能拿到什么东西是吧

智能这事人类连问题是什么 ...</blockquote>
但是人类社会的科学技术的进展大都是如此啊，很多时候就是瞎折腾，造出锤子之后再回头找钉子。

LLM这个方向，现在能明确scaling/benchmark等一系列东西，已经是人类科学史上最有针对性和科学性的那一批了

*****

####  lwezh  
##### 27#       发表于 2024-7-30 13:17

这有什么好心虚的，会用ai就不算工作能力了？有些老登连百度都不会用，最基础的Excel公式百度出来的步骤详解都看不懂，一个5分钟就能搞定的表在那装模作样的奋斗一天，人家照样心安理得。

*****

####  ZekNagPul  
##### 28#       发表于 2024-7-30 15:30

<blockquote>云卷花开 发表于 2024-7-30 12:51
我不知道我想要啥，也不知道能得到啥，就硬堆堆规模看看我能拿到什么东西是吧

智能这事人类连问题是什么 ...</blockquote>
仿生是非常常见的工程思路

连接主义就是一种仿生。节点，连接权重，激活函数模拟单个神经元行为，网络拓扑模拟神经回路。

*****

####  nukacolamania  
##### 29#       发表于 2024-7-30 15:32

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65742248&amp;ptid=2193277" target="_blank">玉米黍 发表于 2024-7-30 11:40</a>
可以预见未来网络上和大街上都会充斥着AI提供的无实际意义的信息内容。</blockquote>
往回倒退十年，人手写的各种新闻稿是什么有实际意义的内容产出吗<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">

—— 来自 motorola moto g stylus 5G (2022), Android 13上的 [S1Next-鹅版](https://github.com/ykrank/S1-Next/releases) v3.0.0.81-alpha

*****

####  13号  
##### 30#       发表于 2024-7-30 15:38

公司对 commit 要求比较高，每次 commit 写个合适的文案有时候挺烦的，还得额外检查语法对不对。

最近本地起了个 ollama 服务，然后用 gemma2 的 7B 的模型，搞个小脚本每次把git diff 内容扔过去，生成的 commit 信息合适就直接用，不合适就直接让他重生成，效果太好了。

*****

####  星花  
##### 31#       发表于 2024-7-30 15:44

 本帖最后由 星花 于 2024-7-30 15:47 编辑 
<blockquote>ZekNagPul 发表于 2024-7-30 15:30
仿生是非常常见的工程思路

连接主义就是一种仿生。节点，连接权重，激活函数模拟单个神经元行为，网络拓 ...</blockquote>

不是应该搞生物大脑么?一堆大脑并联比计算机有趣多了。把人大脑挖空，连上人造脑网络，放入社会里学习，才是最有效的。

*****

####  ZekNagPul  
##### 32#       发表于 2024-7-30 16:04

 本帖最后由 ZekNagPul 于 2024-7-30 16:06 编辑 
<blockquote>星花 发表于 2024-7-30 15:44
不是应该搞生物大脑么?一堆大脑并联比计算机有趣多了。把人大脑挖空，连上人造脑网络，放入社会里学习， ...</blockquote>

没有湿件发展的空间，低性能，不稳定

类脑计算有方向也是存内计算，光量子忆阻器什么的

*****

####  星花  
##### 33#       发表于 2024-7-30 16:09

 本帖最后由 星花 于 2024-7-30 16:17 编辑 
<blockquote>ZekNagPul 发表于 2024-7-30 16:04
没有湿件发展的空间，低性能，不稳定

类脑计算有方向也是存内计算，光量子忆阻器什么的 ...</blockquote>

方向错了 再努力也没用。ai 耗能那么高 还整天乱说话。计算机 才是性能低 不稳定的一方。生物脑自带自我意识，主要控制用，数据计算可以交给计算机完成。与其用没意识的进行模仿，不如直接用有自我意识的。把情感去除，耗能会更好。

*****

####  shikiki  
##### 34#       发表于 2024-7-30 16:11

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65742685&amp;ptid=2193277" target="_blank">lin2004 发表于 2024-7-30 12:17</a>
Ai这玩意如果成本（部署训练使用）下不来无法塞进手机或者个人电脑里离线玩，那最后只会成为得跟高铁一样的 ...</blockquote>
现在还有什么东西你不联网就可以获取到信息的……要的就是联网然后让ai 自己去检索搜集信息然后汇总给我，现在信息大爆炸，很多事情你花钱去咨询也不一定可以得到准确回复，毕竟你咨询的人也是人他无法无休止去给你汇总信息…除非你是马云有几百人的律师团队……

*****

####  yanjunle  
##### 35#       发表于 2024-7-30 16:19

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65741687&amp;ptid=2193277" target="_blank">逆天的小鼠人 发表于 2024-7-30 10:54</a>

是的，对于重复性文书工作，即使是7B小模型也可以做得很好，反正最后都要读一遍

目前我比较担心的是，目前 ...</blockquote>
[https://leaderboard.lmsys.org](https://leaderboard.lmsys.org)

gpt4o-mini在这个纯主观pvp榜单上能排到第二，说明至少大语言模型爱好者群体已经分辨不出今天顶级模型的好坏了

*****

####  zhaowenyi7  
##### 36#       发表于 2024-7-30 16:20

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65741980&amp;ptid=2193277" target="_blank">逆天的小鼠人 发表于 2024-7-30 11:17</a>

我不相信存在涌现这个现象

我更加偏向于涌现的表象是人类对于AI智能水平的评价并非线性的结果 ...</blockquote>
会取名讲故事罢了，如果大模型是1B1B的加上去的规模，可能评价指标也就是一个线性增长，取个涌现的名字好像他突然获得了智能一样。幻觉这个词也是同理，所谓幻觉其实就是bad case，只不过从分类任务的1认成2变成了预测任务的token1变成token2

*****

####  逆天的小鼠人  
##### 37#       发表于 2024-7-30 16:27

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65742218&amp;ptid=2193277" target="_blank">右代宫嘉音 发表于 2024-7-30 11:38</a>

现在gpt4o写代码能力真的牛逼，我十几年码农通过这个大幅度提升工作效率。当然现在我手下完全无法像我一 ...</blockquote>
是的，所以我把程序员单独拎了出来，因为程序员这个工作的特殊性，生成的文本内容可以通过运行程序进行检测，同时对代码的准确性又有高度要求，那么即使些微的提升也能在使用上体现出来，同时也有大量高质量的文本供给学习

而其他专业领域则缺乏数据，不缺乏数据的普通文书工作，又不在意准确性

*****

####  蓝泽玲  
##### 38#       发表于 2024-7-30 16:32

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65741687&amp;ptid=2193277" target="_blank">逆天的小鼠人 发表于 2024-7-30 10:54</a>
是的，对于重复性文书工作，即使是7B小模型也可以做得很好，反正最后都要读一遍

目前我比较担心的是，目前 ...</blockquote>
<img src="https://static.saraba1st.com/image/smiley/face2017/020.png" referrerpolicy="no-referrer">有的本来是非生成类任务当生成类任务做的时候，7b小模型基本得不到好的结果。比如涉及大量专业名词的命名实体关系识别、逻辑推理、数学计算。

*****

####  逆天的小鼠人  
##### 39#       发表于 2024-7-30 16:38

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65745132&amp;ptid=2193277" target="_blank">yanjunle 发表于 2024-7-30 16:19</a>

https://leaderboard.lmsys.org

gpt4o-mini在这个纯主观pvp榜单上能排到第二，说明至少大语言模型爱好者 ...</blockquote>
嗯，还需要进一步观察，因为第一是gpt4o，这也有可能是openAI现在技术跨层第一导致的

*****

####  逆天的小鼠人  
##### 40#       发表于 2024-7-30 16:39

 本帖最后由 逆天的小鼠人 于 2024-7-30 16:42 编辑 
<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65745260&amp;ptid=2193277" target="_blank">蓝泽玲 发表于 2024-7-30 16:32</a>

有的本来是非生成类任务当生成类任务做的时候，7b小模型基本得不到好的结果。比如涉及大量专业名词的命名 ...</blockquote>
但是不太可能有人把这种工作交给LLM，来进行生产力行为，因为完整大模型，实际上表现也好不到哪里去

而对于单纯 scale up 能否突破这一层，我不是很有自信，我更倾向于实用思路，让 LLM 学会处理准确数值计算时调用计算器


*****

####  Zurlg  
##### 41#       发表于 2024-7-30 16:46

我现在写稿都开着ai来，用来润色，查错别字，整理语句通顺都很好用


*****

####  ZekNagPul  
##### 42#       发表于 2024-7-30 16:52

<blockquote>星花 发表于 2024-7-30 16:09
方向错了 再努力也没用。ai 耗能那么高 还整天乱说话。计算机 才是性能低 不稳定的一方。生物脑自带自我 ...</blockquote>
哈哈 未来靠你了 去写作业吧小朋友

﹍﹍﹍

评分

 参与人数 1战斗力 +1

|昵称|战斗力|理由|
|----|---|---|
| 星花| + 1|虽然我不爽，但还是加分。|

查看全部评分

*****

####  星花  
##### 43#       发表于 2024-7-30 16:55

<blockquote>ZekNagPul 发表于 2024-7-30 16:52
哈哈 未来靠你了 去写作业吧小朋友</blockquote>
谢谢，给你加一分^O^


*****

####  ZekNagPul  
##### 44#       发表于 2024-7-30 17:00

<blockquote>zhaowenyi7 发表于 2024-7-30 16:20
会取名讲故事罢了，如果大模型是1B1B的加上去的规模，可能评价指标也就是一个线性增长，取个涌现的名字好 ...</blockquote>
本来AlexNet,ResNet也存在涌现现象啊

LLM能力肯定不是线性的，很容易理解，欠参数化模型无法形成对任务的内化，拥有良好的泛化能力


*****

####  javamailman  
##### 45#       发表于 2024-7-30 17:04

<blockquote>逆天的小鼠人 发表于 2024-7-30 10:54
是的，对于重复性文书工作，即使是7B小模型也可以做得很好，反正最后都要读一遍

目前我比较担心的是，目前 ...</blockquote>

互联网当年低成本吹逼太多了 那时候随便注册个域名小厂就能说搞互联网，而且还叠加加息周期给干崩的。现在好歹还得实打实买卡 而且基本都是大厂的开支多 大厂哪那么容易崩，有亏损其他部门也会输血不至于破产


*****

####  十六夜鬼月  
##### 46#       发表于 2024-7-30 17:13

<blockquote>ZekNagPul 发表于 2024-7-30 12:04
涌现是一种广泛存在于复杂系统的特性，不局限于LLM

超导，相变这些物理现象都属于涌现。生命本质是一种 ...</blockquote>
自然界存在涌现是可能的，因为自然界信息以模拟信号为主，先天就总有不确定性。基于二进制计算的计算机出现涌现就属于不可能的。因为二进制计算这一底层逻辑就封死了意外的可能。


*****

####  ZekNagPul  
##### 47#       发表于 2024-7-30 17:24

<blockquote>十六夜鬼月 发表于 2024-7-30 17:13
自然界存在涌现是可能的，因为自然界信息以模拟信号为主，先天就总有不确定性。基于二进制计算的计算机出 ...</blockquote>

首先，自然界底层显然是离散的…

其次，离散系统显然存在涌现

最经典的模型：Game of Life的各种pattern了解一下


*****

####  十六夜鬼月  
##### 48#       发表于 2024-7-30 18:23

<blockquote>ZekNagPul 发表于 2024-7-30 17:24
首先，自然界底层显然是离散的：普朗克时间，普朗克长度，能级，自旋…

其次，离散系统显然存在涌现
</blockquote>
首先数字信号是离散的≠离散的就是数字信号。

其次，不论你上层算法怎么变，底层逻辑只要还是二进制，那它所有的计算结果都是可以确定的，可以与输入数值一一对应，也就是结果终究会在一个值域范围内。如果有意外，那不是计算过程中有什么神奇结果，大概率是处理器坏了。

*****

####  寇马可  
##### 49#       发表于 2024-7-30 18:25

你还是摸的太少，没法心安理得偷薪水<img src="https://static.saraba1st.com/image/smiley/face2017/067.png" referrerpolicy="no-referrer">


*****

####  ZekNagPul  
##### 50#       发表于 2024-7-30 18:43

 本帖最后由 ZekNagPul 于 2024-7-30 18:45 编辑 
<blockquote>十六夜鬼月 发表于 2024-7-30 18:23
首先数字信号是离散的≠离散的就是数字信号。

其次，不论你上层算法怎么变，底层逻辑只要还是二进制，那 ...</blockquote>

和数字信号有什么关系，说了涌现本质是计算不可约性，无法通过基本单元逻辑推导出系统行为。整体大于单元之和。

另外其实你的问题是二律背反中的关于自由意志的那条，如果基本规则是确定性的，初始条件是确定的，那么自由意志是否存在。你在假定自然不是决定论的，但是计算机是决定论的。所以基于二进制的计算机怎么能模拟自然智能。

好吧，自由意志本来就不存在。只是还是由于K复杂度和计算不可约性，虽然某种程度上来说世界是决定论的（但是还有我们没搞清楚的量子坍缩和观测者问题），但是个人意志和世界的因果关系无法通过什么简化系统简化计算进行预测。


*****

####  逆天的小鼠人  
##### 51#       发表于 2024-7-30 19:51

 本帖最后由 逆天的小鼠人 于 2024-7-30 19:53 编辑 

现在的 第二次涌现 对于AI从业者来讲是一个不能回答 否 的问题

我虽然坐在一个叫 通用人工智能 的实验室，但是因为已经做了另寻出入的准备所以也不怎么在意，我是认为第一次涌现都需要打问好，更不用说还没到来的第二次了

在今后我认为 AI 会回到一个趋于冷静但仍然值得研究的位置，不至于像 control is dead 那么死，也不至于像 群智能 那么水，归根结底 AI 继承的是 Machine learning 的衣钵，而 Machine Learning 作为研究对象本身还是科研工具的底子都太好了


*****

####  4396777  
##### 52#         楼主| 发表于 2024-7-30 20:15

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65746388&amp;ptid=2193277" target="_blank">寇马可 发表于 2024-7-30 18:25</a>

你还是摸的太少，没法心安理得偷薪水</blockquote>
一个办公室就四个人，一个我，一个老板，一个人事，一个财务，老板甚至还在外地出差，确实没有那么心安理得<img src="https://static.saraba1st.com/image/smiley/face2017/068.png" referrerpolicy="no-referrer">


*****

####  一座恐怖屋  
##### 53#       发表于 2024-7-31 11:43

<blockquote><a href="httphttps://bbs.saraba1st.com/2b/forum.php?mod=redirect&amp;goto=findpost&amp;pid=65747132&amp;ptid=2193277" target="_blank">逆天的小鼠人 发表于 2024-7-30 19:51</a>

现在的 第二次涌现 对于AI从业者来讲是一个不能回答 否 的问题

我虽然坐在一个叫 通用人工智能 的实验室， ...</blockquote>
所以我一直觉得智能本身就是故事和包装，但只要不陷入智能玄学的追求，确实切实的会增加各种重复和查询效率，对工业化大生产解放生产力大有好处


*****

####  ZekNagPul  
##### 54#       发表于 2024-7-31 11:53

<blockquote>一座恐怖屋 发表于 2024-7-31 11:43
所以我一直觉得智能本身就是故事和包装，但只要不陷入智能玄学的追求，确实切实的会增加各种重复和查询效 ...</blockquote>
这一轮革命初始阶段和工业自动化没什么关系

工业自动化是传统控制论的天下，能自动的部分早自动了，没自动的部分缺的不是算法是执行器

执行器的颠覆（高通用任务能力机器人）要具身智能和机器人领域进一步迭代，这一块最先落地的是自动驾驶，不会是工业生产

